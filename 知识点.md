# *知识点*

## 一、Linux

### 1.1 常用命令

####  1.1.1 lsof（list open files）

* 一个列出当前系统打开文件的工具。

* 常用的用法：

  ```shell
  lsof -i      # 列出所有网络连接
  lsof -i:80   # 查看使用80端口的文件
  lsof -i:udp  # 查看所有udp网络连接信息
  lsof -i:tcp  # 查看所有tcp网络连接信息
  lsof -i udp:55  # 查看谁在使用某个特定的udp端口
  lsof -i tcp:3306  # 查看设在使用某个特定的tcp端口
  lsof -a -u test -i  # 列出test用户所有活跃的网络进程
  lsof -p pid  # 列出pid对应的文件信息
  ```

#### **1.1.2 netstat**

* 一个监控TCP/IP网络的工具，它可以显示路由表、实际的网络连接以及每一个网络接口设备的状态信息。

* 常用参数

  ```shell
  -a(all)		# 显示所有选项，默认不显示LISTEN相关
  -t(tcp)		# 显示tcp相关选项
  -u(udp)		# 显示udp相关选项
  -n			# 拒绝显示别名，能显示数字的全部转化成数字
  -l			# 列出有在listen的服务状态
  -p			# 显示进程及进程id
  ```

+ 常用命令：

  ```shell
  netstat -a		# 列出所有端口
  netstat -au		# 列出所有udp端口
  netstat -at 	# 列出所有tcp端口
  netstat -l		# 列出监听端口
  netstat -alput	# 列出所有的tcp、udp信息，并显示pid
  # netstat 一般搭配grep命令使用
  ```

#### 1.1.3 top

* 用来监控Linux的系统状况，是常用的性能分析工具，能够实时的显示各个进程的资源占用情况

* 信息说明

  ![image-20200726101921746](https://img-blog.csdnimg.cn/20200809213855365.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxNzYyODYxNzk0,size_16,color_FFFFFF,t_70)

  * 第一行:

    |             内容             |                             含义                             |
    | :--------------------------: | :----------------------------------------------------------: |
    |           18:19:08           |                         表示当前时间                         |
    |          up  39 min          |                   系统运行时间，格式为h：m                   |
    |           1 users            |                        当前登录用户数                        |
    | load average:0.08, 0.06,0.14 | 系统负载，三个数值分别是1分钟，5分钟，15分钟前到现在的平均值。如果这个数除以逻辑cpu的数量结果高于5的时候就表明系统在超负荷运转了。 |

  * 第二行：

    |   内容    |       含义       |
    | :-------: | :--------------: |
    | 338 total |     进程总数     |
    | 1 running | 正在运行的进程数 |
    | 260 sleep |   睡眠的进程数   |
    | 0  stoped |   停止的进程数   |
    | 0 zombie  |    僵尸进程数    |

  * 第三行

    |  内容   |                     含义                      |
    | :-----: | :-------------------------------------------: |
    | 0.4 us  |             用户空间占用CPU百分比             |
    | 0.3 sy  |             内核空间占用CPU百分比             |
    | 0.0 ni  | 用户进程空间内改变过优先级的进程占用CPU百分比 |
    | 99.3 id |                 空闲CPU百分比                 |
    | 0.0 wa  |          等待输入输出的CPU时间百分比          |
    | 0.0 hi  |             硬中断占用CPU的百分比             |
    | 0.0 si  |             软中断占用CPU的百分比             |
    | 0.0 st  |                                               |

  * 第四行

    |      内容      |         含义         |
    | :------------: | :------------------: |
    |   xxx total    |     物理内存总量     |
    |    xxx used    |  使用的物理内存总量  |
    |    xxx free    |     空闲内存总量     |
    | xxx buff/cache | 用作内核缓存的内存量 |

  * 第五行

    |     内容      |                  含义                  |
    | :-----------: | :------------------------------------: |
    |  xxx  total   |            使用的交换区总量            |
    |   xxx  used   |             空闲交换区总量             |
    |   xxx free    |            缓冲的交换区总量            |
    | xxx avail Mem | 代表可用于进程下一次分配的物理内存数量 |

#### 1.1.4 grep

#### 1.1.5 sed

> 流编辑器，实现对文字的增删改替换查（过滤，取行），能同时处理多个文件多行的内容，可以不对原文件改动，把整个文件输入到屏幕，可以把只匹配到的模式输入到屏幕上，还可以对源文件改动，但是不会在屏幕上返回结果

##### 1.1.5.1 使用

* **语法**：

  ```shell
  sed [-hnV][-e<script>][-f<script文件>][文本文件]
  ```

* **参数说明：**
  * -e<script>或--expression=<script>
    * 以选项中指定的script来处理输入的文本文件
  * -f<script文件>或--file==<script文件>
    * 以选项中指定的script文件来处理输入的文本文件
  * -h或--help
    * 显示帮助
  * -n或--quiet或--silent
    * 仅显示script处理后的结果
  * -V或--version
    * 显示版本信息
* **动作说明**
  * **a**：新增，a的后面可以接字符串，而这些字符串会在新的一行出现
  * **c**：替换，c的后面可以接字符串，这些字串可以取代n1，n2之间的行
  * **d**：删除，因为是删除，所以d后面不接任何东西
  * **i**：插入，i的后面可以接字符串，而这些字符串会在新的一行出现
  * **p**：打印，亦即将某个选择的数据印出，通常p会与参数sed -n一起裕兴
  * **s**：替换，可以直接用正则进行替换。

* 测试文件：

  ```shell
  # testfile
  HELLO LINUX!  
  Linux is a free unix-type opterating system.  
  This is a linux testfile!  
  Linux test 
  ```

  

#### 1.1.6 awk

##### 1.1.6.1 简介

1. awk是一种编程语言，用于对文本和数据进行处理
2. 具有强大的文本格式化能力
3. 利用命令awk，可以将一些文本整理成为我们想要的样子
4. 命令awk是逐行进行的

##### 1.1.6.2 使用

* 使用文件`log.txt`,文件内容如下：

  ```cpp
  2 this is a test
  3 Are you like awk
  This's a test
  10 There are orange,apple,mongo
  ```

* **用法一**

  ```shell
  awk '{[pattern] action}' {filenames} #行匹配语句awk ''只能用单引号
  ```

  实例：

  ```shell
  # 每行按照空格或者tab分割，输出文本中的1、4项
  $ awk '{print $1,$4}' log.txt
  ---------------------------------------------
  2 a
  3 like
  This's
  10 orange,apple,mongo
  
  # 格式化输出
  $ awk '{printf "%-8s %-10s\n",$1,$4}' log.txt
  ---------------------------------------------
  2        a
  3        like
  This's
  10       orange,apple,mongo
  ```

* **用法二**：

  ```shell
  awk -F # -F相当于内置变量FS，指定分割字符
  ```

  实例：

  ```shell
  #使用，号分割
  $ awk -F, '{print $1,$4}' log.txt
  ---------------------------------------------
   2 this is a test
   3 Are you like awk
   This's a test
   10 There are orange apple
  # 或者使用内建变量
  $ awk 'BEGIN{FS=","}{print $1,$4}' log.txt
  ---------------------------------------------
   2 this is a test
   3 Are you like awk
   This's a test
   10 There are orange apple
  
  # 使用多个分隔符。首先使用空格分割，然后对风格结果再使用","分割
  $ awk -F "[ ,]" '{print $1,$2,$3}' log.txt
   2 this test
   3 Are awk
   This's a
   10 There apple
  ```

  * **用法三**

  ```shell
  awk -v # 设置变量
  ```

  实例：

  ```shell
  $ awk -va=1 '{print $1,$1+a}' log.txt
  ---------------------------------------------
   2 3
   3 4
   This's 1
   10 11
  $ awk -va=1 -vb=s '{print $1,$1+a,$1b}' log.txt
  ---------------------------------------------
   2 3 2s
   3 4 3s
   This's 1 This'ss
   10 11 10s
  ```

* **用法四**

  ```shell
  awk -f {awk脚本} {文件名}  # 加载awk脚本运行
  ```

  实例：

  ```shell
  # cal.awk
  # '{print $1,$4}'
  $ awk -f cal.awk log.txt
  ---------------------------------------------
   2 a
   3 like
   This's 
   10 orange,apple,mongo
  ```

* **其他**

  ```powershell
  $ awk '$1>2' log.txt  # 过滤第一列大于2的行 
  ---------------------------------------------
   3 Are you like awk
   This's a test
   10 There are orange,apple,mongo
  $ awk '$1==2{print $1,$2,$3}' log.txt #过滤第一列等于2的行
  ---------------------------------------------
   2 is
  $ awk '$1>2 && $2=="Are"{print $1,$2,$3}' log.txt # 过滤第一列大于2并且第二列等于“Are”的行
  ---------------------------------------------
   3 Are you
  ```

##### 1.1.6.3 内建变量

|              变量               |                            描述                            |
| :-----------------------------: | :--------------------------------------------------------: |
| <font color=red>**`$n`**</font> |            当前记录的第n个字段，字段间由FS分隔             |
| <font color=red>**`$0`**</font> |                      完整的输入的整行                      |
|             `ARGC`              |                      命令行参数的目录                      |
|             `ARGV`              |                    包含命令行参数的数组                    |
|            `CONVFMT`            |    数字转换格式（默认值为%6.g）ENVIRON环境变量关联数组     |
|             `ERRNO`             |                   最后一个系统错误的描述                   |
|          `FILEDWIDTHS`          |                字段宽度列表（用空格键分隔）                |
|         **`FILENAME`**          |           当前文件名（使用管道输入FILENAME为空）           |
|            **`FNR`**            |                      文件当前行的行号                      |
|            **`FS`**             |                   字段分隔符，默认是空格                   |
|        **`IGNORECASE`**         |               如果为真，则忽略大小写进行匹配               |
| <font color=red>**`NF`**</font> |                    一条记录的字段的数目                    |
| <font color=red>**`NR`**</font> |                     当前行号，从1开始                      |
|             `OFMT`              |                数字的输出格式(默认值是%.6g)                |
|              `OFS`              | 输出记录分隔符（输出换行符），输出时用指定的符号代替换行符 |
|              `ORS`              |             输出记录分隔符(默认值是一个换行符)             |
|            `RLENGTH`            |              由match函数所匹配的字符串的长度               |
|              `RS`               |                记录分隔符(默认是一个换行符)                |
|            `RSTART`             |           由match函数所匹配的字符串的第一个位置            |
|            `SUBSEP`             |                数组下标分隔符(默认值是/034)                |
|                                 |                                                            |

* **正则匹配**

  ```shell
  # 输出第二列包含“th”，并打印第二列与第四列
  $ awk '$2 ~ /th/ {print $2,$4}' log.txt  # ~表示模式开始，//中是模式
  ---------------------------------------------
   this a
  
  # 输出包含“re”的行
  $ awk '/re/' log.txt
  ---------------------------------------------
   3 Are you like awk
   10 There are orange,apple,mongo
  ```

##### 1.1.6.4 awk脚本

```shell
BEGIN{
	这里面放的是执行前的语句
}
{
	这里放的是处理每一行时要执行的语句
}
END{
	这里面放的是处理完所有的行后执行的语句
}
```

* 测试文件`score.txt`

  ```cpp
  Marry   2143 78 84 77
  Jack    2321 66 78 45
  Tom     2122 48 77 71
  Mike    2537 87 97 95
  Bob     2415 40 57 62
  ```

* awk脚本

  ```shell
  # !/bin/awk -f
  # 运行前
  BEGIN{
  	math = 0
  	english = 0
  	computer = 0
  	
  	printf "NAME\tNO.\tMATH\tENGLISH\tCOMPUTER\tTOTAL\n"
  	printf "-----------------------------------------\n"
  }
  # 运行中
  {
  	math+=$3
  	english+=$4
  	computer+=$5
  	printf "%-4s %-4s %4d %8d %8d %8d\n",$1,$2,$3,$4,$5,$3+$4+$5
  }
  # 运行后
  END{
  	printf "-----------------------------------------\n"
  	printf "\tTOTAL:%10d %8d %8d \n",math,english,computer
  	printf "AVEARAGE:%10.2f %8.2f %8.2f\n",math/NR,english/NR,computer/NR
  }
  ```

  执行结果：

  ```shell
  $ awk -f cal.awk score.txt
  NAME    NO.   MATH  ENGLISH  COMPUTER   TOTAL
  ---------------------------------------------
  Marry  2143     78       84       77      239
  Jack   2321     66       78       45      189
  Tom    2122     48       77       71      196
  Mike   2537     87       97       95      279
  Bob    2415     40       57       62      159
  ---------------------------------------------
    TOTAL:       319      393      350
  AVERAGE:     63.80    78.60    70.00
  ```

  * 其他实例

    ```shell
    # 打印99乘法表
    $ seq 9 | sed 'H;g' | awk -v RS='' 'for(i=1;i<=NF;i++)printf("%dx%d=%d%s",i,NR,NR*i,i==NR?"\n":"\t")}'
    ----------------------------------------------------
    1x1=1
    1x2=2	2x2=4
    1x3=3	2x3=6	3x3=9
    1x4=4	2x4=8	3x4=12	4x4=16
    1x5=5	2x5=10	3x5=15	4x5=20	5x5=25
    1x6=6	2x6=12	3x6=18	4x6=24	5x6=30	6x6=36
    1x7=7	2x7=14	3x7=21	4x7=28	5x7=35	6x7=42	7x7=49
    1x8=8	2x8=16	3x8=24	4x8=32	5x8=40	6x8=48	7x8=56	8x8=64
    1x9=9	2x9=18	3x9=27	4x9=36	5x9=45	6x9=54	7x9=63	8x9=72	9x9=81
    ```

    

#### 1.1.7 GDB

##### 1.1.7.1 启动

> GDB调试
>
> 启动程序准备调试：
>
> `gdb yourpragma`
>
> 或者
>
> `gdb`-->`file yourpragma`
>
> 然后
>
> 使用`run`或者`r`命令开始程序的执行

##### 1.1.7.2 命令

|      命令      | 命令缩写 |                           命令说明                           |
| :------------: | :------: | :----------------------------------------------------------: |
|      list      |    l     |                         显示多行源码                         |
|     break      |    b     |               设置断点，程序运行到断点会停下来               |
|      info      |    i     |                        描述程序的状态                        |
|      run       |    r     |                         开始运行程序                         |
|    display     |   disp   |           跟踪查看某个变量，每次停下来都显示它的值           |
|      step      |    s     | 执行下一条语句，如果该语句为函数调用，则进入函数执行其中第一条语句 |
|      next      |    n     |  执行下一条语句，如果该语句为函数调用，不会进入函数内部执行  |
|     print      |    p     |                       打印内部变量的值                       |
|    continue    |    c     |              继续程序的运行，知道遇到下一个断点              |
| set var name=v |          |                         设置变量的值                         |
|     start      |    st    |          开始执行程序，在main函数的第一条语句停下来          |
|      file      |          |                      装入需要调试的程序                      |
|      kill      |    k     |                      终止正在调试的程序                      |
|     watch      |          |                      监视变量的值的变化                      |
|   backtrace    |    bt    |                    查看函数的调用堆栈信息                    |
|     frame      |    f     |                           查看栈帧                           |
|      quit      |    q     |                         退出GDB环境                          |

##### 1.1.7.3 多线程调试命令

|          命令           |                             用法                             |
| :---------------------: | :----------------------------------------------------------: |
|      info threads       | 显示当前可调试的所有线程，每个线程会有一个GDB为其分配的ID，后面操作线程的时候回用到这个ID。前面有*号的是当前调试的线程 |
|        thread ID        |               切换当前调试的线程为指定ID的线程               |
| break file:5 thread all |                 在所有线程相应的行上设置断点                 |
|           ...           |                             ...                              |

##### 1.1.7.4 条件断点

> 顾名思义，这种断点是当满足一定条件时才会触发，比较适合异常排查
>
> `b line-or-function  if(condition)`
>
> 比如：`b test.cpp:12 if value == 5`

### 1.2 多线程下的锁

#### 1.2.1 互斥锁（Linux）

同一时刻只有一个线程能持有该锁，其余线程等待持有锁的线程释放锁之后才能获得该锁，等待锁的线程进入阻塞状态。

#### 1.2.2 读/写锁（Linux）

* 读锁

  读锁之间是共享的，一个线程加读锁之后，其余线程可以加读锁，但是不能加写锁，读锁和写锁互斥

* 写锁

  写锁就相当于一个互斥锁，加上了写锁之后不能再加任何锁。

* 适用的场景：

  适用于读多写少的场景

#### 1.2.3 自旋锁（Linux）

自旋锁是一种特殊的锁，当资源被加锁之后，该线程不是被阻塞而是陷入循环，一直检查锁是否释放。释放了就获取该锁。

* 优缺点：

  优点是减少了线程从睡眠到唤醒的消耗，缺点是一直占用CPU资源

* 使用场景：

  适用于资源被锁住的时间短，而又不希望在线程的唤醒上浪费资源的情况。
  
  

#### 1.2.4 乐观锁

##### 1.2.4.1 定义

* 顾名思义，就是很乐观，每次获取数据时都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有无更新这个数据。可使用版本号等机制。乐观锁适用与读多的应用场景，可提高系统的吞吞吐率。
* 乐观锁假设数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式的对数据的冲突与否进行检测，如果发现了冲突，则让返回用户错误的信息，让用户决定如何去做。乐观锁并不使用数据库的锁机制。

##### 1.2.4.2 实现方式

乐观锁的概念中其实已经阐述了它的实现细节：主要是两个步骤：冲突检测和数据更新。其中实现方式比较典型的就是**Compare And Swap（CAS）**和**版本号机制**

* **CAS是一项乐观锁技术**，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其他的线程都失败，失败的线程并不会挂起，而是被告知这次竞争失败，并可以再次尝试。

* **CAS**

  CAS包括了3个操作数：

  ```cpp
  1）需要读写的内存位置（V)
  2）进行比较的预期值（A）
  3）拟写入的新值（B)
  ```

  * **CAS的逻辑操作如下**：

    如果内存位置V的值等于预期的A值，则将该位置更新为新值B，否则不进行其他操作。

    许多CAS的操作是自旋的：如果操作不成功会一直重试，直到成功为止。

    **CAS是由CPU支持的原子操作，其原子性在硬件层面得以保证**

* CAS会出现的问题：

  * **ABA问题**：比如说一个线程one从数据库中取出库存数3，这时候另一个线程two也从数据库中取出库存数3，并且two进行了一些操作变成了2，然后two又将库存数变成3，这时候线程one进行CAS操作发现数据库中仍然是3，然后one操作成功。尽管线程one的CAS操作成功，但是不代表这个过程就是没有问题的。

    * **解决办法**：通过一个单独的可以顺序递增的字段，比如版本号、时间戳来解决这个问题。（CAS加版本号，保证CAS的正确）

      乐观锁每次在执行数据修改操作是，都会带上一个版本号，一旦版本号和数据的版本号一致就可以执行修改操作，并对版本号执行加一操作，否则就执行失败。因为每次操作版本号都会随之增加，所以不会出现ABA问题。

  * **高竞争下的开销问题**。在并发冲突概率较大的环境下，如果CAS一致失败，会一直重试，CPU开销较大
  * **功能限制**。CAS的功能是比较受限的，例如CAS只能保证单个变量（或者说单个内存值）操作的原子性。设计到多个变量（内存值）的时候CAS无能为力。

  

* **直接使用版本号机制。**

  * **版本号机制：**

    版本号机制的思路是在数据中增加一个字段version，表示该数据的版本号，每当数据被修改时，版本号加一

    * 当某个线程查询数据时，将该数据的版本号一起查询出来
    * 当该线程更新数据时，判断当前版本号与之前读取的版本号是否一致，如果一致才进行操作。

#### 1.2.5 悲观锁

##### 1.2.5.1 定义

* 顾名思义，就是很悲观，每次获取数据的时候都认为别人会修改，所以每次拿到数据都会加锁，这样别人想要获取这个数据就会阻塞直到有锁可拿。传统关系型数据库里边就用到了很多这种锁机制。他指的是对数据被外界修改时持保守态度，因此在整个数据处理过程中，将数据置于锁定状态，往往依靠数据库提供的锁机制。

* 之所以叫悲观锁，是因为这一种对数据修改抱有悲观态度的并发控制方式。其认为数据被并发修改的概率比较大，所以需要在修改之前先加锁、悲观并发控制实际上是“先加锁后访问”的保守策略，为数据处理的安全提供了保证。但是在效率方面，处理加锁的机制会让数据库产生额外的开销，还有增加产生死锁的机会，还会降低并行性。

##### 1.2.5.2 实现方式

悲观锁的实现往往依靠数据库提供的锁机制，在数据库中，悲观锁的流程如下：

* 在对记录进行修改前，先尝试为该记录加上排他锁
* 如果加锁失败了，说明该记录正在被修改，那么当前查询可能要等待或者抛出异常
* 如果成功加锁，那么就可以对数据进行修改，事务完成后就会解锁
* 期间如果有其他事务对该记录做出修改，则会阻塞或者抛出异常



#### 1.2.6 公平锁

线程按照他们申请锁的顺序获取锁，公平锁就是很公平，在并发环境下，每个线程在获取锁时会查看此锁维护的等待队列，如果队列为空，获取当前线程时等待队列的第一个就占有锁，否则就会加入到等待队列中，以后会按照FIFO的规则从队列中获取锁。

#### 1.2.7 非公平锁

是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请锁的线程先获取到锁，但是在高并发的情况下，可能会造成优先级翻转或者饥饿现象。

#### 1.2.8 可重入锁（又名递归锁）

指的是同一个线程外层函数获得锁后，内层递归函数任能获取该锁。在同一个线程外层函数获取锁的时候，在进入内层方法会自动的获取锁。

### 1.3 进程和线程

#### 1.3.1 进程间通信的方式：

* 管道

  * 有名管道

    > 在磁盘上会存储一个管道文件标识（inode），但是不会占据磁盘空间，数据不会存储到磁盘上

    * 使用mkfifo创建管道，产生的命名管道在文件系统中存在
    * **可以在没有亲缘关系的进程之间通信**

  * 无名管道

    > 利用文件描述符作为读写管道

    * 使用pipe创建管道，一个文件描述符数组fds，fds[0]为读端，fds[1]为写端
    * **只能用于父子进程之间的通信**

* 信号

* 信号量

* 消息队列

  * **消息队列是由消息组成的链表，存放在内核中并由消息队列标识符标识**。有写权限的进程可以向队列中添加消息，拥有读权限的进程则可以读去队列中的消息。
  * **消息队列克服了信号承载信息量较少，管道只能承载无格式字节流以及缓冲区大小受限制等缺点**

* 共享内存

  * 共享内存的意思是，同一块物理内存被映射到进程A、B各自的进程空间。进程A可以即时看到进程B对共享内存中数据的更新，反之亦然。
  * <font color=red>通信效率最高，因为不涉及进程间任何数据传输</font>

* 套接字

#### 1.3.2 线程间通信的方式

* 互斥量
* 条件变量
* 信号量

#### 1.3.3 僵尸进程和孤儿进程

##### 	1.3.3.1 僵尸进程

> 对于多进程程序而言，父进程一般需要跟踪子进程的退出状态。因此，当子进程结束运行时，内核不会立即释放该进程的进程表表项，以满足父进程后续对该子进程退出信息的查询（如果父进程还在运行）

* 子进程进入僵尸态的两种情况

  * 在子进程结束运行之后，父进程读取其退出状态之前，我们称该子进程处于僵尸态。
  * 父进程结束或者异常终止，而子进程继续运行。此时子进程的PPID将会被设置为1，即init进程。init进程接管了该子进程，并等待它结束。在父进程退出之后，在子进程退出之前，该子进程处于僵尸态。

* 避免/杀死僵尸进程

  * 避免僵尸进程

    * 使用下面这对函数在父进程中调用，以等待子进程的结束，并获取子进程的返回信息，从而避免了僵尸进程的产生，或者使子进程的僵尸态立即结束。

      ```cpp
      #include <sys/types.h>
      #include <sys/wait.h>
      
      pid_t wait(int * stat_loc);
      pid_t waitpid(pid_t pid,int* stat_loc,int options);
      
      ```

    * `wait`函数将阻塞进程，直到该进程的某个子进程结束运行为止。它返回结束运行的子进程的PID，并将该子进程的退出状态信息存储于stat_loc参数指向的内存信息中

    * `waitpid`只等待由pid参数指定的子进程。如果pid=-1，那么它就和wait函数相同。

    * 这两个函数一般配合一个信号`SIGCHLD`使用。当一个进程结束时，他将给其父进程发送一个`SIGCHLD`信号。当信号触发时，设置一个回调函数，用于调用`wait`和`waitpid`函数接收子进程的返回信息。

  * 杀死僵尸进程

    * 杀死其父进程（kill，但kill杀不了僵尸进程）
    * 重启系统

##### 1.3.3.2 孤儿进程

> 一个父进程退出，而它的一个或多个子进程还在运行，那么这些子进程就会成为孤儿进程。孤儿进程将被init进程收养（进程号为1），并由init进程对他们完成转态收集工作。

### 1.4  硬链接和软连接

> 为了解决文件共享的问题，Linux引入了软连接和硬链接。除了为Linux解决文件共享问题，还带来了隐藏文件路径、增加权限安全及节省存储等好处。

* **硬链接**
  * 若一个inode号对应多个文件名，则为硬链接，即硬链接就是同一个文件使用了不同的别名，使用`ln`创建。硬连接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬连接到重要文件，以防止“误删”的功能
* **软链接**
  * 若文件用户数据块中存放的内容是另一个文件的路径指向，则该文件是软链接。软链接是普通文件，有自己独立的inode，但是其数据块内容比较特殊。

## 二、操作系统

### 2.1 内存管理

#### 2.1.1 无存储器抽象

* 每个程序都直接访问物理内存
* 在内存中同时运行2个程序是不可能的，因为这两个程序的地址有可能冲突，造成程序的崩溃
* 如果要在无存储器抽象上运行多个程序，操作系统只需要把当前内存中所有内容保存到磁盘文件中，然后把下一个程度读到内存中运行即可。只要在某一个时间内存中只有一个程序，就不会发生冲突
* 无存储器抽象的缺点：
  * 直接修改物理内存，容易破坏操作系统，从而使系统慢慢停止运行
  * 同时运行多个程序很难实现

#### 2.1.2 一种存储器抽象：地址空间

> 地址空间是一个进程可用于寻址内存的一套地址集合，每个进程都有一个自己的地址空间，并且这个地址空间独立于其他进程的地址空间

地址空间为程序创造了一种抽象的内存。

* 问题在于给每一个程序一个自己独有的地址空间。使得程序A的地址28所对应的物理地址和程序B中地址28所对应的物理地址不同
* 针对上述问题，可以使用**动态重定位**，经典的办法是使用两个寄存器：**基址寄存器**和**界限寄存器**。当一个程序运行时，程序的其实物理地址装载到基址寄存器，程序的长度装载到界限存储器。
  * 缺点：每次访问内存都需要进行加法和比较运算，速度较慢

#### 2.1.3 交换技术

* 一种用于处理内存超载的技术，即把一个程序完整调入内存，使该进程运行一段时间，然后把它存回磁盘
* 交换技术会在内存中产生大量的空闲区，虽然可以通过内存紧缩来将小的空闲区合成一大块，但内存紧缩会占用大量的CPU时间。

#### 2.1.4 虚拟内存

* 虚拟内存的基本思想

  > 每个程序拥有自己的地址空间，这个空间被分割成很多个块，每个块称作**一页**或**页面**。每一页有连续的地址范围，这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行。
  >
  > 当程序引用到一部分在物理内存中的地址空间时，由硬件立即执行必要的映射。当程序引用到一部分不再物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存，并重新执行失败的指令。

* 使用虚拟内存的目的：

  * 保护操作系统，使程序无法直接访问物理内存地址
  * 解决内存超载的问题。将程序全部加载到内存，内存太小则可能无法运行程序，虚拟内存实现可以只加载需要的一部分到内存中运行。
  * 实现同时运行多个程序而互不影响

* 虚拟内存实现的技术有：分页，分段，段页式

##### 2.1.4.1 分页

分段即将程序的地址空间按照固定大小划分为页或者页面，物理内存划分的单元称为页框，通常页框大小和页面相同。页面被加载到物理内存（即和页框进行映射），但并不是所有的页面都加载到内存程序才能运行。页表用于保存页面和页框的映射关系，页表里的一条条页表项就是页面和页框的映射。当程序引用一部分页面时，若页面已经被加载到物理内存，则立即执行映射，若没有加载到物理内存，则引起一个缺页中断，由操作系统复杂将缺失的页面装载到内存。

* 分页需要解决的两个问题
  * 虚拟地址到物理地址的映射要非常快（使用快表TLB）
  * 虚拟地址空间非常大，页表也会很大（使用多级页表和倒排页表）

* 页面置换算法：
  * LRU，最近最少使用算法

##### 2.1.4.2 分段

> 将程序的地址空间划分为多个相互独立的称为段的地址空间，每个段由一个从0到最大线性地址序列构成，每个段可以独立的增长或减小而不会影响到其他的段。

* 分段适合处理在执行过程中大小有变化的数据结构。
* 分段的优点有简化链接和共享，有利于为不同的段提供不同保护

##### 2.1.4.3 段页式

* 结合了分段和分页的优点
  * 分段：易于编程、模块化、保护和共享
  * 分页：统一的页面大小，使用时不需要全部装载到内存

### 2.2 死锁

#### 2.2.1 死锁的定义

> 如果一个进程集合中的每个进程都在等待只能由该进程集合中的其他进程才能引发的事件，那么该进程集合就是死锁的。

#### 2.2.2 死锁产生的必要条件

* **互斥条件**。每个资源要么分配给一个进程，要么就是可用的
* **占有和等待条件**。已经得到某个资源的进程可以再请求新的资源
* **不可抢占条件**。已经分配给一个进程的资源不能被强制性的抢占，它只能被占有它的进程显示的释放。
* **环路等待条件**。死锁发生时，系统中一定有两个或两个以上的进程组成一条环路，该环路中的每个进程都爱等待着下一个进程所占有的锁。

#### 2.2.3 处理死锁的策略

##### 2.2.3.1 忽略该问题

* 鸵鸟算法，遇见死锁当做不存在。如果死锁的频率很低、死锁的代价很小的时候，花费大量的代价去处理死锁有可能是不划算的

##### 2.2.3.2 检测死锁并恢复

* 死锁的检测和预防

  在使用这种技术时，系统并不试图阻止死锁的发生，而是允许死锁的发生，当检测到死锁发生后，采取措施进行恢复。

  * 死锁的恢复方法：
    * 利用抢占恢复
    * 利用回滚恢复
    * 通过杀死进程恢复

##### 2.2.3.3 仔细对资源进行分配，动态避免死锁

* 死锁避免

  * 银行家算法

    * 算法要做的是判断对请求的满足是否会导致进入不安全状态。

    * 安全状态和不安全状态的区别是：从安全状态触发，系统能够保证所有的进程都能完成；而从不安全状态出发，则没有这样的保证。

##### 2.2.3.4 通过破坏死锁的四个必要条件，防止死锁发生

* 死锁预防
  * 破坏互斥条件
  * 破坏占有并等待条件。请求资源时，先释放已有的资源，然后再次获取
  * 破坏不可抢占条件。
  * 破坏环路等待条件

#### 2.2.4 活锁

在某些情况下，当进程意识到它不能获取所需要的下一个锁时，就会释放已经获得的锁，并重新尝试获取锁。如果有两个进程交叉获取锁，则会一直处于上诉的循环中，称为活锁。

#### 2.2.5 饥饿

假如CPU优先执行优先级较高的进程，则优先级较低的进程可能永远不会执行，因为系统中有可能一直存在优先级大于最低优先级进程的进程，这种情况就是饥饿。

### 2.3 进程和线程

#### 2.3.1 进程和线程的区别

1. 进程是系统资源分配的基本单位，线程是CPU调度的基本单位
2. 线程属于进程，一个进程可以有一个或多个进程
3. 进程的创建、销毁和上下文切换开销大于进程
4. 进程编程调试相对简单但开销较大，线程编程调试相对复杂但开销较小
5. 进程和线程的通信方式不相同
6. 进程之间相互独立，互不影响，但一个线程挂掉可能会影响整个进程挂掉

### 2.4 协程

#### 2.4.1 定义

> 协程，又称微线程，纤程（Coroutine）。
>
> 协程（Coroutine）是一种轻量级的用户态线程，实现的是非抢占式的调度，即由当前协程切换到其他协程由当前协程来控制。目前的协程框架一般都是设计成 1:N 模式。所谓 1:N 就是一个线程作为一个容器里面放置多个协程。

协程看上去也是子程序（函数），但在执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。注意，在一个子程序中中断，去执行其他子程序，不是函数调用，而是有点类似CPU的中断。

#### 2.4.2 优点

1. **协程更加轻量，创建成本更小，降低内存消耗**

   协程本身可以做在用户态，每个协程的体积比线程要小得多，因此一个线程可以容纳相当可观的协程

2. **协作式的用户态调度器，减少了CPU上下文切换的开销，提高了CPU命中率**

   协作式的调度相比抢占式调度的优势在于上下文切换开销更少、更容易把缓存跑热。和多线程相比，线程数量越多，协程的性能优势就越明显。进程和线程的切换需要在内核完成，而切成不需要，协程通过用户态栈实现，更加轻量，速度更快。

3. **减少同步加锁，整体上提高了性能**
   协程方案基于事件循环方案，减少了同步加锁的频率。但若存在竞争，并不能保证临界区，因此该上锁的地方人需要加上协程锁

4. **可以按照同步的思维写异步代码，即用同步代码的逻辑，写由协程调度的回调**

#### 2.4.3 缺点

1. 在协程执行中不能有阻塞操作，否则整个线程被阻塞（协程是语言级别的，线程、进程是操作系统级别的）
2. 需要特别关注全局变量，对象引用的使用
3. 协程可以处理IO密集型程序的效率问题，但是处理CPU密集型不是它的长处

### 2.5 内核态和用户态

内核态和用户态是操作系统的两种运行级别，两者最大的区别就是特权级不同。用户态拥有最低的特权级，内核态拥有较高的特权级。运行在用户态的程序不能直接访问操作系统内核数据结构和程序。用户态和内核态之间的转换方式主要包括：系统、异常和中断

### 2.6 生产者消费者

使用信号量机制进行同步

```cpp
#define N 100
typedef int semaphore;
semaphore mutex = 1;
semaphore empty = N;
semaphore full = 0;

void producer(){
    int item;
    while(true){
        item = produce_item();		//生产数据
        down(empty);
        down(mutex);
        insert_item(item);  		//将数据添加到临界区
        up(mutex);
        up(full);
    }
}

void consumer(){
    int item;
    while(true){
        down(full);
        down(mutex);
        item = remove_item(); 		//将数据从临界区移除
        up(mutex);
        up(empty);
    }
}
```



## 三、数据库

### 3.1 MySQL

#### 3.1.1 MySQL架构

和其他数据库相比，MySQL有点与众不同，它的架构可以在多种不同场景中应用并发挥良好作用。主要体现在存储引擎的架构上，**插件式的存储引擎架构将查询处理和其他的系统任务以及数据的存储提取相分离**。这种架构可以根据业务的需求和实际需要选择合适的存储引擎

* **连接层**。最上层是一些客户端和连接服务。**主要完成一些类似于连接处理、授权认证及相关的安全方案**。在盖层上引入了线程池了概念，为通过认证安全接入的哭护短提供线程。同样在该层上可以实现基于SSL的安全链接。服务器也会为安全接入的每个客户端验证它所具有的操作权限。
* **服务层**。第二层服务层，主要完成大部分的核心服务功能，包括查询解析、分析、优化、缓存以及所有的内置函数，所有跨存储引擎的功能也都在这一层实现，包括触发器、存储过程、视图等
* **引擎层**。第三层存储引擎层，存储引擎真正的负责了MySQL中数据的存储和提取，服务器通过API与存储引擎进行通信。不同的存储引擎具有的功能不同，这样我们可以根据自己的实际需要进行选取
* **存储层**。第四层为数据存储层，主要是将数据存储在运行于该设备的文件系统上，并完成与存储引擎的交互

##### 3.1.1.1 MySQL的查询流程

```text
客户端请求-->连接器（验证用户身份，给予权限）
-->查询缓存（存在缓存则直接返回，不存在则执行后续操作）
-->分析器（对SQL进行词法分析和语法分析）
-->优化器（主要对执行的SQL优化选择最优的执行方案方法）
-->执行器（执行时会先看用户是否有执行权限，有才去使用这个引擎体提供的接口）
-->去引擎层获取数据返回（如果开启查询缓存则会缓存查询结果）
```

![image-20200729170619399](https://img-blog.csdnimg.cn/20200809213855651.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxNzYyODYxNzk0,size_16,color_FFFFFF,t_70)



#### 3.1.2 MySQL存储引擎

> 存储引擎是MySQL的组件，用于处理不同表类型的SQL操作。不同的存储引擎提供不同的存储机制、索引技巧、锁定水平等功能，使用不同的存储引擎还可以获得特定的功能
>
> MySQL服务器使用**可插拔**的存储引擎体系结构，可以从运行中的MySQL服务器加载或卸载存储引擎

##### 3.1.2.1 MySQL常见存储引擎

* **<font color=red>InnoDB</font>**
* **MyISAM**
* **Memory**
* **NDB**

**MySQL现在默认的存储引擎是InnoDB，支持事务、行级锁和外键**

##### 3.1.2.2 InnoDB和MyISAM

1. InnoDB支持事务，MyISAM不支持事务。这是MySQL将默认存储引擎从MyISAM装换位InnoDb的重要原因之一
2. InnoDB支持外键，而MyISAM不支持。对一个包含外键的InnoDB表转为MyISAM会失败
3. InnoDB是聚簇索引，MyISAM是非聚簇索引。聚簇索引的文件存放在主键索引的叶子节点上，因此InnoDB必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此主键不应该过大，因为主键太大，其他索引也都会很大。而MyISAM是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的
4. InnoDB不保存表的具体行数，执行`select count(*) from table`时需要全表扫描。而MyISAM使用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快。
5. InnoDB最小的锁粒度是行锁，MyISAM最小的粒度是表锁。



#### 3.1.2 MySQL索引

##### 3.1.2.1 索引的定义

> MySQL官方对索引的定义为：索引是帮助MySQL高效获取数据的数据结构，所以说索引的本质是：数据结构

##### 3.1.2.2 索引的优缺点

* 优点
  * 提高数据检索效率，降低数据库IO成本
  * 降低数据排序的成本，降低CPU消耗
* 缺点
  * 索引也是一张表，保存了主键和索引字段，并指向实体表的记录，所以也需要占用内存
  * 虽然索引提高了查询速度，但同时也会降低更新表的速度。维护索引有一定的开销

##### 3.1.2.3 索引的分类

* 数据结构角度
  * B+索引
  * Hash索引
  * Full-Text全文索引
  * R-Tree索引
* 物理存储角度
  * 聚集索引（属于B+索引）

    > 聚集索引就是按照每张表的主键构造一颗B+树，并且叶节点存放着整张表的行记录数据，因此也让聚集索引的叶节点称为数据页。每个数据页都通过一个双向链表连接，以加快相邻数据的查查询。聚集索引只能有一个一张表。

  * 非聚集索引，也叫辅助索引（属于B+索引）

    > 叶节点除了包含键值以外，还包含了一个指向对应行数据的书签。当痛过辅助索引来查找数据时，InnoDB存储引擎会遍历辅助索引并通过叶节点的指针获得指向主键索引的主键，再通过主键索引来找到一个完整的行记录。辅助索引可以有多个

  * 两者都是B+数结构
* 从逻辑角度
  * 主键索引：主键索引是一种特殊的唯一索引，不允许有空值
  * 普通索引或者单列索引：每个索引只包含单个列，一个表可以有多个单列索引
  * 多列索引（复合索引、联合索引）：复合索引值多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用符合索引是遵循最左前缀集合
  * 唯一索引或非唯一索引
  * 空间索引



#### 3.1.3 MySQL事务

##### 3.1.3.1 事务的特性

* **A（Atomicity）原子性：**整个事务中的所有操作，要么全部完成，要么全部不完成，不可能处于中间某个环节。执行中间出现错误，会被回滚到事务开始前的状态
* **C（Consistency）一致性：**在事务开始之前和事务结束以后，数据库的完整性约束没有背破坏。事务只能从一个一致性状态到另一个一致性状态
* **I（Ioslation）隔离性**：一个事务的执行不能被其他事物干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发事务之间不能互相干扰
* **D（Durability）持久性：**在事务完成以后，该事务对数据库所做的更改便持久的保存在数据库中，并不会被回滚

##### 3.1.3.2 并发事务处理带来的问题

* **丢失更新**：事务A和事务B选择同一行，然后基于最初选定的值更新该行时，由于两个事务都不知道彼此的存在，就会发生丢失更新的问题
* **脏读**：事务A读取到了事务B未提交的数据，简单来说就是可以读到脏数据。事务B对一行数据进行修改，此时事务A读取到了该行，但是事务B回滚了，所以事务A读取到了脏数据。
* **不可重复读**：事务A多次读取同一数据，事务B在事务A多次读取的过程中，对数据做了更新并提交，导致事务A多次读取同一数据时，结果不一致
* **幻读**：幻读与不可重复读类似。他发生在一个事务A读取了几行数据，接着另一个并发事务B插入了一些数据时，在随后的查询中，事务A就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。

##### 3.1.3.3 事务隔离级别

* **READ-UNCOMMITTED（读未提交）**：最低的隔离级别，允许读取尚未提交的数据变更，可能导致**脏读，幻读或不可重复读**
* **READ-COMMITTED（读已提交）**：允许读取并发事务已经提交的数据，可以**阻止脏读、但是不可重复读、幻读任然有可能发生**
* **REPEATABLE-READ（可重复读）**：对同一字段的多次读取结果都是一致的，除非数据是被本事务自己所修改，可以**阻止脏读和不可重复读，但幻读任有可能发生**。InnoDB在此隔离级别下使用`Next-Key Lock`锁算法，避免幻读产生，所以MySQL在当前隔离级别就达到的SQL标准的SERIALIZABLE级别。
* **SERIALIZABLE（可串行化）**：最高的隔离界别，完全服从ACID的隔离级别。所有事务一次逐个执行，这样书屋之前就完全不可能产生干扰。

##### 3.1.3.4 MVCC多版本并发控制

* MySQL的大多数事务型存储引擎实现都不是简单的行级锁。基于提升并发性考虑，一般都同时实现了多版本并发控制（MVCC）。

* 可以认为MVCC是行级锁的一个变种，但它在很多情况下避免了加锁操作，因此开销更低，虽然实现机制有所不同，但大都实现了非阻塞的读操作，写操作也只是锁定必要的行
* MVCC的实现是通过保存数据在某个时间点的快照来实现的。也就是说，不管需要执行多长的时间，每个事务看到的数据都是一致的
* 典型的MVCC的实现方式，分为**乐观并发控制**和**悲观并发控制**。
  * InnoDB的MVCC是通过在每行记录后面保存两个隐藏的列来实现。这两个列一个保存了行的创建时间，一个保存了行的过期时间。当然存储的并不是真实的时间，而是系统版本号。每开始一个新的事务，系统版本号就会自动递增，事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。

##### 3.1.3.5 事务的实现

* 事务的隔离性是通过锁实现的，而事务的原子性、一致性和持久性则是通过事务日志实现的
  * **redo log（重做日志）**：实现持久化和原子性
    * 在innoDB的存储引擎中，事务日志通过重做(redo)日志和innoDB存储引擎的日志缓冲(InnoDB Log Buffer)实现。事务开启时，事务中的操作，都会先写入存储引擎的日志缓冲中，在事务提交之前，这些缓冲的日志都需要提前刷新到磁盘上持久化，这就是DBA们口中常说的“日志先行”(Write-Ahead Logging)。当事务提交之后，在Buffer Pool中映射的数据文件才会慢慢刷新到磁盘。此时如果数据库崩溃或者宕机，那么当系统重启进行恢复时，就可以根据redo log中记录的日志，把数据库恢复到崩溃前的一个状态。未完成的事务，可以继续提交，也可以选择回滚，这基于恢复的策略而定。
    * 在系统启动的时候，就已经为redo log分配了一块连续的存储空间，以顺序追加的方式记录Redo Log，通过顺序IO来改善性能。所有的事务共享redo log的存储空间，它们的Redo Log按语句的执行顺序，依次交替的记录在一起。
  * **undo log（回滚日志）**：实现一致性
    * undo log 主要为事务的回滚服务。在事务执行的过程中，除了记录redo log，还会记录一定量的undo log。undo log记录了数据在每个操作前的状态，如果事务执行过程中需要回滚，就可以根据undo log进行回滚操作。单个事务的回滚，只会回滚当前事务做的操作，并不会影响到其他的事务做的操作。
    * Undo记录的是已部分完成并且写入硬盘的未完成的事务，默认情况下回滚日志是记录在表空间中的（共享表空间或者独享表空间）



#### 3.1.4 锁

##### 3.1.4.1 锁的算法

+ Record Lock

> 单个行记录上的锁，行锁

+ Gap Lock

> 锁定一个范围，但不包含记录本身，间隙锁

+ Next Key Lock

> Gap Lock + Record Lock,锁定一个范围，并锁定记录本身。在REPEATABLE  READ模式下，Next-Key  Lock是默认的行记录锁定算法。临键锁

##### 3.1.4.2 锁升级

锁升级是指将当前锁的粒度降低。

##### 3.1.4.3 加锁机制

**乐观锁与悲观锁是两种并发控制的思想，可用于解决丢失更新问题**

* **乐观锁**会“乐观的”假定大概率不会发生并发更新冲突，访问、处理数据的过程中不加锁，只是在更新的时候再根据版本号或时间戳判断是否有冲突，有则处理，无则提交事务。用数据版本记录机制实现，这是乐观锁最常用的一种方式。
* **悲观锁**会“悲观的”假定大概率会发生更新冲突，访问，处理数据前就加排他锁，在整个数据处理的过程中锁定该数据，事务提交或者回滚才释放该锁，悲观锁是由数据库实现的。

#### 3.1.5  B树

##### 3.1.5.1 前言

B（Balance Tree）和B+树都是应用在数据库索引，可以认为是认为m叉的**多路平衡查找树**，但从理论上讲二叉树的查找和比较次数都是最小的，为什么不用二叉树？

因为我们需要考虑磁盘IO的影响，它相对于内存来说是很慢的。数据库索引是存储在磁盘上的，当数据量大的时候就不能把整个索引全部加载到内存了，只能逐一加载每个磁盘页（对应索引树的节点）。所以我们需要减少IO的次数，对于树来说，IO次数就是树的高度，而“矮胖”就是B树的特征之一，它的每个节点最多包含m个孩子，m称为B树的阶，m的大小取决于磁盘页的大小。

##### 3.1.5.2 M阶B树的特征

1. 定义任意非叶子节点最多只有M个儿子，且M>2
2. 根节点的儿子数为[2,M]
3. 除根节点以外的飞叶子节点的儿子数为[M/2,M],向上取整
4. 飞叶子节点的关键字个数=儿子数-1
5. 所有的叶子节点位于同一层
6. k个关键字把节点拆成k+1段，分别指向k+1个儿子，同时满足查找树的大小关系

##### 3.1.5.3 B树的特性

1. 关键字集合在整棵树中
2. 任何一个关键字只出现在一个节点中
3. 搜索有可能在非叶子节点结束
4. 其搜索性能等价于在关键字全集内做一次二分查找

#### 3.1.6 B+树

B+树是B树的一种变体，查询性能更好。

##### 3.1.6.1 B+树的特征

1. 有n棵子树的非叶子节点中含有n个关键字（B树是n-1个），这些关键字不保存数据，只用于索引，所有数据都保存在叶子节点（B树是每个节点都保存数据）
2. 所有叶子节点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子节点本身依关键字的大小自小而大的连接
3. 所有的叶子节点可以看成是索引部分，节点中仅包含其子树中的最大（或最小）关键字
4. 通常在B+树上有两个头指针，一个指向根节点，一个指向关键字最小的节点
5. 同一个关键字会在不同节点重复出现，根节点的最大元素就是B+树的最大元素

##### 3.1.6.2 B+树相对于B树的优势

1. B+树的中间节点不保存数据，所以磁盘页能容纳更多的节点元素，更加“矮胖”
2. B+树查询必须要查询到叶子节点，B树只要匹配到即可，不用管元素的位置，因此B树查找更加稳定
3. 对于范围查找来说，B+树只需要遍历叶子节点链表即可，B树却需要重复地中序遍历。

### 3.2 Redis

#### 3.2.1 五种基础类型和其底层实现

* **字符串**
  * 底层实现
    * int编码的字符串
    * embstr编码
    * raw编码（SDS）
  * 底层编码转换规则
    * 当int编码保存的字符串不是整形时，将从int->raw
    * 当embstr被修改时，将从embstr->raw
* **列表**
  * 底层实现
    * 压缩列表（ziplist）
    * 双端链表（linkedlist）
  * 转换规则
    * 列表对象所有字符串的长度都小于64字节
    * 列表对象元素数量小于512个
    * **满足上述两个条件，则采用`ziplist`**
* **哈希**
  * 底层实现
    * 压缩列表（ziplist）
    * 字典（hashtable）
  * 转换规则
    * 哈希对象保存的所有键值对的键和值的字符串长度都小于64字节
    * 哈希对象元素数量小于512个
    * **满足上述两个条件，则采用`ziplist`**
* **集合**
  * 底层实现
    * 整数集合（intset）
    * 字典（hashtable）
  * 转换规则
    * 集合对象保存的所有元素都是整数值
    * 集合对象的元素不超过512个
    * **满足这两个条件，则使用`intset`**
* **有序集合**
  * 底层实现
    * 压缩列表（ziplist）
    * 跳跃表（skiplist）
    * 字典（hashtable）
  * 转换规则
    * 有序结合保存的所有成员的长度都小于64字节
    * 有序几个保存的元素数量小于128个
    * **满足上述这两个条件，则使用`ziplist`**
  * **`zset`同时使用`skiplist`和`hashtable`来保存有序集合元素**。单独使用`skiplist`可以保证范围操作快速实现，但无法实现查找单个元素`O(1)`;单独使用`hashtable`可以保证单个元素`O(1)`，但无法保证范围操作的快速实现。所以同时使用两种数据结构。

#### 3.2.2 Redis分布式锁

##### 3.2.2.1  实现要点

1. **互斥性**。同一时刻只能有一个客户端持有锁
2. 防止死锁发生，如果持有锁的客户端没有释放锁，也要保证锁可以正常释放及其他客户端可以加锁
3. 加锁和解锁必须是同一客户端
4. **容错性**。只要Redis还有节点存活，就可以进行正常的加锁和解锁操作

##### 3.2.2.2 实现

1. 保证互斥使用的是Redis中的`setnx(set if not exist)`
2. 防止死锁采用的方法是给锁加一个超时时间，时间到自动释放锁

##### 3.2.2.3 问题

* 使用`setnx`获取一个锁之后，客户端崩溃，锁无法释放
  * 给获取到的锁都加一个超时时间，时间到后其他客户端可以继续获得这个锁
* 客户端获得一个锁，设置超时时间，但在客户端任务执行完毕时，超时时间已经过期，并且这个锁被其他的客户端持有，此时，第一个客户端就有可能释放第二个客户端的锁
  * 设置锁key的值为一个随机值，标志是当前客户端加锁。当释放的时候判断其值是否和这个随机值相同，相同才释放锁。但是判断值和胸痛和执行删除命令不是原子性的，所以需要使用**Lua脚本保证原子性**

#### 3.2.3 Redis持久化

##### 3.2.3.1 RDB

> 将Redis在内存中的数据保存到磁盘里面，避免数据的以外丢失。RDB既可以手动执行，也可以自动执行，将数据保存到一个RDB文件中

* 执行RDB持久化的两个命令：`save`和`bgsave`,`save`会阻塞当前进程，直到持久化完成，`bgsave`会`fork`出一个子进程执行RDB
* Redis没有主动还行的载入RDB文件的命令，只有启动Reds时自动加载RDB文件
* RDB的优先级低于AOF，AOF开启时，优先使用AOF回复数据
* 可以设置`save`自动执行的条件来让服务器自动执行RDG持久化

##### 3.2.3.2 AOF

> AOF是通过保存Redis服务器所执行的写命令来记录数据库数据的

* AOF持久化机制维护一个`aof_buf`来存放提交的命令，用于提高效率，命令先存入`aof_buf`,然后根据服务器采取的策略来将`aof_buf`中的命令同步到AOF文件中。
* 有三种AOF持久化策略
  * **`always`**：安全性最好，效率最差
  * **`everysec`**：安全性好，丢失只会丢失1s的数据
  * **`no`**：效率高，但安全性差
* 为了解决AOF文件膨胀的问题，AOF有重写功能，**AOF重写是对现有数据库的数据读取来实现的，无需操作AOF文件**
* 后台重写AOF也是通过`fork`子进程实现的

#### 3.2.4 Redis渐进Hash

随着操作的不断执行，哈希表保存的键值对会组件地增多或者减少，为了让哈希表的负载因子维持在一个合理的范围内，当哈希表保存的键值对数量太多或者太少时，程序需要对哈希表进行相应的扩展或者收缩。

扩展和收缩哈希表的工作可以通过执行`rehash`重新散列的操作来完成，Redis对字典的哈希表执行rehas操作如下：

1. 为字典的`ht[1]`哈希表分配空间，这个哈希表的空间取决于要执行的操作，以及`ht[0]`当前包含的键值对数量（也即是`ht[0].used`属性的值0）：
   * 如果执行的是扩展操作，那么`ht[1]`的大小为第一个大于等于`ht[0].used*2`的2<sup>n</sup>(2的n次幂)
   * 如果执行的是收缩操作，那么`ht[1]`的大小为第一个大于等于`ht[0].used`的2<sup>n</sup>(2的n次幂)
2. 将保存在`ht[0]`中的所有键值对rehash到`ht[1]`上面，：rehash指的是重新计算键的哈希值和索引值，然后将键值对放置到`h[1]`哈希表的指定位置上
3. 当`ht[0]`包含的所有键值对都迁移到`ht[1]`之后（`ht[0]`变为空），释放`ht[0]`,将`ht[1]`设置为`ht[0]`,并在`ht[1]`创建一个空白哈希表，为下一次的rehash作为准备

**渐进式哈希**：

* 在字典中维护一个索引计数器变量`rehashidx`，并设置为0，表示rehash工作正式开始。
* 在rehash执行期间，每次对字典执行的添加、删除、查找或者更新操作时，程序出了执行指定的操作之外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当rehash工作完成之后，程序将rehashidx属性的值增加一。
* 随着字典操作的不断进行，最终在某个时间点上，ht[0]的所有键值对都会被rehash到ht[1],这时程序将rehashidx设置为-1，表示rehash完成
* **渐进式hash的好处在于它采取分而治之的方式，将rehash的键值对所需的计算工作均摊到对字典的每个添加、删除、查找和更新操作上，从而避免了集中式rehash1而带来的庞大计算量**
* 渐进式hash过程中的hash表操作：
  * 对删除、查找、更新会操作两个哈希表，如查找会先查找ht[0],如果ht[0]没有则查找ht[1].
  * 对插入则会直接插入到ht[1]

## 四、计算机网络

### 4.1 TCP

#### 4.1.1 概述

* TCP是**面向连接的**
* TCP是**点对点的**
* TCP提供**可靠交付服务**
* TCP提供**全双工通信**
* TCP是**面向字节流的**

#### 4.1.2 三次握手

![image-20200727210013858](https://img-blog.csdnimg.cn/20200809214111101.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxNzYyODYxNzk0,size_16,color_FFFFFF,t_70)

* 为什么要三次握手？
  * 防止已失效的连接请求报文段突然传送到了B，因而产生错误。假定出现这样一种异常的情况，即A发送的第一个连接请求报文没有丢失，而是在某些网络节点长时间滞留了，以致延误到连接释放以后的某个时间才到达B。本来这是一个早已失效的报文段，但B接收到此失效的连接请求报文段后，就误认为是A又发出一次连接请求，于是就向A发出确认报文段，同意建立连接，加入没有第三次握手，那么只要B发出确认，新的连接就建立了。由于现在A并没有发出建立连接的请求，因此不会理睬B的确认，也不会向B发送数据，但B却以为连接已经建立，并一直等待A发来的数据。
  * 防止SYN泛洪攻击。攻击者向大量的TCP SYN报文段，而不完成三次握手的第三步。由于服务器在收到客户端发来的SYN报文之后，会分配并初始化连接变量和缓存，然后发送一个SYN+ACK报文进行响应，在收到客户端的ACK报文之前，连接并没有完全建立，这种状态称为**半开连接**。如果客户端不发送第三次ACK报文，那么服务器会在一定时间内中止该半开连接，并回收分配资源。SYN泛洪攻击就会使服务器不断为这些半开连接分配资源，导致服务器的连接资源耗尽。
  
* <font color=red>**三次握手可以携带数据**</font>

  * RFC793文档里带有SYN标志的过程包是不可以携带数据的，也就是说三次握手的前两次是不可以携带数据的（逻辑上看，连接还没建立，携带数据好像也有点说不过去）。但第三次可以携带数据。

  * 通过查看源码，找到处理TCP连接各个状态时的收到数据包的处理工作的函数：

    ![在这里插入图片描述](https://img-blog.csdnimg.cn/20200816103552552.png#pic_center)

    这个函数实际上是个TCP状态机，用于处理TCP连接处于各个状态时收到数据包的处理工作。这里有几个并列的switch语句，因为函数很长，所以比较容易看错层次关系。下图是精简了无需关注的代码之后SYN-RECV状态的处理过程：

    ![在这里插入图片描述](https://img-blog.csdnimg.cn/20200816103115341.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxNzYyODYxNzk0,size_16,color_FFFFFF,t_70#pic_center)

    一定要注意这两个switch语句是并列的。<font color=red>**所以当TCP_SYN_RECV状态收到合法规范的二次握手包之后，就会立即把socket状态设置为TCP_ESTABLISHED状态，执行到下面的TCP_ESTABLISHED状态的case时，会继续处理其包含的数据**</font>（如果有）。

  * 客户端处于SYN-SEND状态时，怎么发送第三次ACK包。

    ![在这里插入图片描述](https://img-blog.csdnimg.cn/202008161042274.png#pic_center)

    tcp_rcv_synsent_state_process函数的实现比较长，这里直接贴出最后的关键点：

    ![在这里插入图片描述](https://img-blog.csdnimg.cn/2020081610422752.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxNzYyODYxNzk0,size_16,color_FFFFFF,t_70#pic_center)

    一目了然吧？<font color=red>**if 条件不满足直接回复单独的ACK包，如果任意条件满足的话则使用inet_csk_reset_xmit_timer函数设置定时器等待短暂的时间。这段时间如果有数据，随着数据发送ACK，没有数据回复ACK**</font>。

    

#### 4.1.3 四次挥手

![image-20200728104554629](https://img-blog.csdnimg.cn/20200809213855536.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxNzYyODYxNzk0,size_16,color_FFFFFF,t_70)

* 为什么在TIME-WAIT状态必须等待2MSL的时间？
  1. 保证A发送的最后一个ACK报文段能够到达B，确保连接的正常关闭，这个ACK报文有可能丢失。
  2. 防止“已失效的连接请求报文段”出现在本连接中。等待2MSL后，就可以使本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接中不会出现这种旧的连接请求报文段。
* 为什么是2MSL？
  1. 为了便于描述，假设有一个处于连接过程的TCP连接，这个连接的两端分别是A和B，其中A是主动关闭连接的一端，因为刚刚向对端发生了针对对端发送过来的FIN报文的ACK，此时正处于TIME_WAIT状态，而B是被动关闭的一端，笔试正处于LAST_ACK状态，在收到最后一个ACK之前它会一直重传FIN报文直至超时。随着时间的流逝，A发送给B的ACK报文会有两种结局：
     * ACK报文在网络中丢失，此时B会重传FIN报文
     * ACK被B收到。我们假设A发送了ACK报文过后一段时间t之后B才收到该ACK，则由有0<t<MSL，因为A并不知道它发出去的ACK要多久对方才能收到，所以A至少要维持MSL时长的TIME_WAIT状态才能保证它的ACK从网络中消失。同时处于LAST_ACK状态的B因为收到了ACK报文，就直接进入了CLOSE状态，而不会向网络发送任何报文。所以这样看，A只需要等待一个MSL就可以了，但是自习一想还是有一定问题的，因为在B收到ACK前的那一瞬间，B可能因为没收到ACK而重传了一个FIN报文，这个报文段要从网络中消失最多好需要等待一个MSL时长，所以A需要等待2MSL

#### 4.1.4 保活计时器

* 作用：解决客户端出现故障断开连接但服务器不知道的情况下浪费服务器资源的问题。
* 服务端每收到一次客户的数据，就重新设置保活计时器，时间的设置通常是**两小时**。若两小时没有收到客户的数据，服务器就发送一个探测报文段，以后每隔75s发送一次，若一连发送10个探测报文段客户任无客户响应，服务器就认为客户端出现了故障，接着就关闭这个连接

#### 4.1.5 流量控制

> 所谓流量控制，就是让发送方的发送速率不要太快，要让接收方来得及接收。发送方的发送窗口不能大于接收方的接收窗口

流量控制往往指的都是点对点通信量的控制，是一个端到端的问题。流量控制要做的是抑制发送端的速率，以便接收端来得及接收

#### 4.1.6 拥塞控制

> 所谓拥塞控制，就是防止过多的数据注入到网络中，这样可使网络中的路由器或链路不至于过载。拥塞控制是一个全局性的过程

* 在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏，这种情况就叫做拥塞。
* 拥塞控制用到的算法
  * **慢开始**
  * **拥塞避免**
  * **快恢复**
  * **快重传**

#### 4.1.7 优缺点

* **优点**：
  * 可靠，稳定的TCP可靠体现在TCP在传输数据之前，会有三次握手来建立连接
  * 在数据传输时，有确认号机制、滑动窗口、超时重传机制、拥塞控制机制
  * 在数据传输完成后，会断开连接来节约系统资源
* **缺点：**
  * 慢、效率低，占用系统资源高，已被攻击。
  * 在传输数据之前都会先建立连接，这会消耗连接时间。
  * 传输过程中，确认机制、重传机制、拥塞控制机制等都会消耗大量的时间，而且每台设备商维护所有的传输连接，而且每个连接都会占有系统的CPU资源、内存硬件资源。

### 4.2 UDP

#### 4.2.1 概述

* UDP是**无连接的**
* UDP是**尽最大努力交付**
* UDP是**面向报文的**
* UDP没有**拥塞控制**
* UDP支持**一对一、一对多、多对一和多对多的交互通信**
* UDP的**首部开销小**

#### 4.2.2 优缺点：

* **优点：**
  * 速度快，比TCP稍安全
* **缺点：**
  * 不可靠、不稳定、在网络环境较差的情况下容易丢包

### 4.3 HTTP

#### 4.3.1 概述

* 支持客户服务器模式
* **简单快速**。客户端向服务器请求数据时，只需传送请求方法和路径
* **灵活**。HTTP允许传输任意类型的对象
* **无连接的**。虽然HTTP使用TCP连接，但通信的双方在交换HTTP报文前不需要先建立HTTP连接
* **无状态的**。同一个客户端第二次访问同一个服务器上的页面时，服务器的响应与第一次被访问时相同

#### 4.3.2 HTTP的状态码

* 1xx：指示信息，表示请求以接收，继续处理

* 2xx：成功，表示请求已被成功接收，处理

  - 200（OK）：客户端请求成功
  - 204（No Content）：无内容，服务器成功处理，但未返回内容。一般用在客户端向服务器发送消息，而服务器不用向客户端返回什么信息。不会刷新页面。
  - 206（Partial Content）：服务器已经完成了部分GET请求（客户端进行了范围请求）。响应报文中包含Content Range制定范围的实体内容。

* 3xx：重定向

  - 301（Moved Permanently）：永久重定向，表示请求的资源已经永久的搬到了其他位置。
  - 302（Found）：临时重定向，表示请求的资源临时的搬到了其他位置。
  - 303（See Other）：临时重定向，应使用GET定向获取请求资源。303和302功能一样，区别只是303明确使用GET访问。
  - 307（Temporary Redirect）：临时重定向，和302含义相同。只是强制使用POST
  - 304（Not Modified）：表示客户端发送附带条件的请求时，条件不满足。返回304时，不包含任何响应的主题。

* 4xx：客户端错误

  - 400（Bad Request）：客户端请求有语法错误，服务器无法理解
  - 401（Unauthorized）：请求未经授权，这个状态代码必须和www-Authenticate报头域一起使用
  - 403（Forbidden）：服务器收到请求，但是拒绝提供服务
  - 404（Not Found）：请求资源不存在
  - 415（Unsupported media type）：不支持的媒体类型

* 500：服务器错误

  - 500（interval Server Error)：服务器发生不可预期的错误

  - 503（Server Unavaliable）：服务器当前不能处理客户请求，一段时间后才可以

#### 4.3.3 HTTP1.0和HTTP1.1的区别

* **缓存处理**。在HTTP1.0中主要使用header里的If-Modified-Since，Expires来作为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略如Entity tag、If-Match等更多可供选择的缓存头来控制缓存策略。
* **带宽优化及网络连接的使用**。HTTP1.0，存在一些浪费带宽的情况，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送了过来，并且不支持断点续传的功能。HTTP1.1则在请求头引入了range域，它允许只请求资源的某个部分，即返回码是206（Partial Content）。
* **错误通知**。在HTTP1.1中新增了24个错误的状态码。如409（Confict）表示请求的资源与资源当前状态发生冲突。410（Gone）表示服务器上的某个资源被永久性的删除了。
* **Host头处理**。在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机，并且他们共享一个IP。HTTP1.1的请求消息和响应消息都应支持Host头域。
* **长连接**。HTTP1.1支持长连接和请求的流水线处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。HTTP1.0每发送一次数据都要建立一次TCP连接，发送完后就断开TCP连接。

#### 4.3.4 HTTP1.1和HTTP2.0的区别

* **多路复用**。HTTP2.0使用了多路复用的技术，做到同一个连接并发处理多个请求，而且并发请求数量比HTTP1.1大了几个量级
* **数据压缩**。HTTP1.1不支持Header数据的压缩，HTTP2.0使用HPACK算法对header的数据进行压缩，这样数据体积小了，在网络上传输就会更快
* **服务器推送**。服务器推送能把卡护短所需要的的资源伴随着index.html一起发送到客户端，省去了客户端重复请求的步骤。正因为没有发起请求，建立连接等操作，所以静态资源通过服务端推送的方式可以极大地提升速度。

#### 4.3.5 会话技术

> 由于HTTP请求是无状态的、无连接的，所以如果需要保存一些信息、记录用户状态的话，就需要借用一些技术，如Cookie和Session。

##### 4.3.5.1 Cookie

* 客户端会话技术，数据存储到客户端
* 浏览器对单个Cookie有大小限制（4kb），以及对同一个域名下的总的Cookie的数量也有限制（20个）

##### 4.3.5.2 Session

* 服务器会话技术，将数据存储到服务器
* Session可以存储任意类型、任意大小的数据，但是对服务器有较大的负担
* Session是通过在Cookie中记录一个Session Id唉实现对用户身份的认证，每次请求客户端都会将这个SessionID发送给服务器。（如果禁用了Cookie，则使用一种叫做URL重写的技术来进行会话的跟踪，即每次HTTP交互，URL后面都会被附加上一个诸如sid=xxx的参数，服务端使用这个参数来识别用户）

##### 4.3.5.3 Cookie和Session的区别

* Session存放数据在服务端，安全；Cookie存放数据在客户端，不安全
* Session存储数据没有限制；Cookie存储数据有限制（4kb）
* Session数据相对安全；Cookie数据相对不安全

### 4.4 HTTPS

> HTTPS是由SSL/TLS+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比HTTP协议更加安全

#### 4.4.1 概述

* HTTPS的加密方式有**对称加密**和**非对称加密**
  * 对称加密用于传输数据
  * 非对称加密用于加密对称加密过程中的密钥

#### 4.4.2HTTPS的握手流程

![](https://img-blog.csdnimg.cn/20200729102345406.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxNzYyODYxNzk0,size_16,color_FFFFFF,t_70#pic_center)



### 4.5 网络协议对比

#### 4.5.1 TCP和UDP的区别

* TCP是面向连接的，保证可靠交付的；UDP是无连接的，尽最大努力交付的
* TCP是点对点通信；UDP可以一对一、一对多、多对一、多对多通信
* TCP首部开销是20字节；UDP首部开销是8字节
* TCP是面向字节流的；UDP是面向数据报的

#### 4.5.2 HTTP和HTTPS的区别

* HTTP以明文传输数据；HTTPS以密文传输数据
* HTTP的端口为80；HTTPS的端口为443
* HTTP不需要CA证书；HTTPS需要CA证书

### 4.6 DNS

> 域名到IP地址的解析过程要点如下：当某一个应用进程需要把主机名解析为IP地址时，该应用进程就调用**解析程序**，并成为DNS的一个客户，把待解析的域名放在DNS在请求报文中，以UDP用户数据报方式发给本地域名服务器（使用UDP是为了减少开销）。本地域名服务器在查找域名之后，把对应的IP地址放在回答报文中返回。应用进程获得目的主机的IP地址后即可立即进行通信
>
> 若本地域名服务器不能回答该请求，则此域名服务器就暂时成为DNS中的另一个客户，并向其他域名服务器发送查询请求，直到找到能够回答该请求的的、域名服务器为止

* **递归查询**

  主机向本地域名服务器查询一般都采用的是**递归查询**。所谓递归查询就是：如果主机所询问的本地域名服务器不知道被查询域名的IP地址，那么本地域名服务器就以DNS客户的身份，向其他根域名服务器发出查询请求报文（即替该主句继续查询），而不是让该主机自己进行下一步查询。因此，递归查询返回的是查询结果或者是所要查询的IP地址，或者是报错，表示无法查询到所需的IP地址。

* **迭代查询**

  本地域名服务器向根域名服务器的查询通常是采用**迭代查询**。迭代查询的特点是：当根域名服务器收到本地域名服务器发出的迭代查询报文时，要么给出所要查询的IP地址，要么告诉本地域名服务器：“你下一步应当向哪一个域名服务器进行查询”。然后让本地域名服务器进行后续的查询（而不是替本地域名服务器进行后续的查询）。本地域名服务器也可以采用递归查询，这取决于最初的查询请求报文设置是要求使用哪一种查询方式。

* **疑问：**
  * 为什么机器在处理IP数据报时要使用IP地址而不使用域名呢？
    * 因为IP地址的长度是固定的32位（如果是IPv6，那就是128位，也是定长的），而域名的长度并不是固定的，机器处理起来比较困难。
  * DNS一个服务器故障还可以正常查询吗？
    * DNS采用的是分布式DNS域名系统。为了保证域名服务器的可靠性，DNS域名服务器都把数据复制到几个域名服务器来保存，其中一个是**主域名服务器**，其他的都是**辅助域名服务器**。当主域名服务器出现故障，辅助域名服务器可以保证服务器正常进行，主域名服务器定期复制数据到辅助域名服务器，而更改数据只能在主域名服务器，这样就保证了数据的一致性。

### 4.7 网络安全

### 4.8 物理层



## 五、数据结构

### 5.1 hash

#### 5.1.1 哈希表的原理

* 散列技术是在记录的存储位置和它的关键字之间建立一个确定的对应关系`f`，是的每个关键字`key`对应一个存储位置`f(key)`
* 对应关系`f`成为散列函数（哈希函数），采用散列技术将记录存储在一块连续的存储空间中，这块连续的存储空间称为**散列表**或**哈希表**

#### 5.1.2 哈希函数的构造方法

* 直接定址法
* 数字分析法
* 平方取中法
* 折叠法
* **除数留余法**
* 随机数法

#### 5.1.3 处理哈希冲突的方法

* 开放定址法
  * 线性探测
* 再散列函数法
* 链地址法

### 5.2 快速排序

#### 5.2.1 快排的基本思想

快排使用分治的思想，通过一趟排序将待排序的序列分为两部分，其中一部分关键字均比一部分小。之后分别对这两部分再排序，以达到其本身有序。

#### 5.2.2 快排的步骤

1. 选择基准
2. 分割操作
3. 递归地对两个字序列排序

#### 5.2.3 选择基准的方式

最理想的是将序列分为两个等长的子序列。

1. 固定位置：第一个或者最后一个元素作为基准。
2. 随机位置：随机选择一个位置作为基准
3. 三数取中：取第一个、最后一个和中间位置三个数，选择其中位数作为基准

#### 5.2.4 快排的优化

1. 当待排序的序列分隔到一定的长度后，使用插入排序。对于序列比较短，插入排序的效率比快速排序更好
2. 在一次分割操作结束后，可以将key值相等的元素聚在一起，下次分隔时，不再对key相等的元素分割。
3. 优化递归操作
4. 使用多线程处理子序列

## 六、网络编程

### 6.1 Libevent库

#### 6.1.1 特点

* 基于事件驱动，高性能
* 轻量级，专注于网络
* 跨平台
* 支持多种IO复用技术，`epoll`，`select`，`poll/dev`,`kqueue`
* 支持信号、定时器和I/O等事件

#### 6.1.2 大体结构

* 并发网络模型使用**Reactor**
* IO事件和`signal`事件存放的数据结构为**链表**
  * `signal`统一到IO复用中使用的是`pipe`或者`socketpair`
* 定时事件存放的数据结构为**小根堆**
  * 定时器统一到IO使用使用的是类似于`epoll_wait`的最大等待时间

### 6.2 IO复用

#### 6.2.1 select

> 在一段时间内，监听用户感兴趣的文件描述符上面的可读、可写和异常事件。API如下
>
> ```cpp
> #include<sys/select.h>
> int select(int nfds,fd_set * readfds,fd_set * writefds,fd_set * exceptfds,struct timeval * timeout)
> ```

##### 6.2.1.1 参数

* **nfds**：待监听的最大fd值+1
* **readfds**：待监听的可读文件fd集合
* **writefds**：待监听的可写文件fd结合
* **execptfds**：待监听的异常文件fd集合
* **timeout**：超时设置，在等待指定时间后返回超时

##### 6.2.1.2 select优点

* 跨平台支持比较好，几乎在所有平台都有支持

##### 6.2.1.3 select的缺点

* 打开的文件描述符有最大值限制，可以自行设置，但是还是取决于服务器的性能
* 对socket进程扫描时是线性的，即采用轮询的方法，效率较低
* 每次调用都会将监控的文件描述符拷贝到内核，开销较大

#### 6.2.2 poll

> poll和select差不多，只是文件描述符同一放到一个`pollfd`链表中了，pollAPI如下：
>
> ```cpp
> int poll(struct poll * fds,nfds_t nfds,int timeout);
> 
> /*pollfd类型的定义*/
> struct pollfd{
>     int fd;
>     short events;
>     short revents;
> }
> ```



#### 6.2.3 epoll

> `epoll`在`select`和`poll`的基础上效率有了较大的提升。API如下：
>
> ```cpp
> #include<sys/epoll.h>
> int epoll_create(int size);
> // 创建一个epoll的实例，同时在内核中开辟一块缓存和创建红黑树，用于存放epoll要监控的fd，
> //创建一个就绪链表，用于存放已经就绪的fd
> // size:指定监控的文件描述符个数，一般没什么用
> 
> int epoll_ctl(int epfd,int op,int fd,struct epoll_event * event);
> //用于操作epoll中的IO事件或者注册IO事件
> // epfd:epoll实例描述符
> // op:操作类型，有三种
> //	 1. EPOLL_CTL_ADD:注册新的fd到epfd中
> //   2. EPOLL_CTL_MOD:修改已经注册的fd的监听事件
> //   3. EPOLL_CTL_DEL:从epoll中删除一个fd
> // fd:需药监控的fd
> // event:告诉内核对注册文件描述符的什么类型的事件进行监听
> 
> // 向内核中注册文件描述符的过程就是在内核的红黑树中添加节点，并未这个节点注册一个回调函数
> 
> // epoll_event数据结构
> struct epoll_event{
>     __uint32_t events; 	//epoll的事件类型
>     epoll_data_t data;  //用户数据变量
> };
> 
> int epoll_wait(int epfd,struct epoll_event * events,int maxevents,int timeout);
> //成功返回就绪的文件描述符的数量，失败返回-1，超时返回0
> //events:存放就绪fd的数组
> //maxevents:最大监听的fd个数
> //timeout:epoll的超时时间
> 
> ```
>

##### 6.2.3.1 epoll实现原理

* 调用`epoll_create`时，会在内核开辟一个高速cache区，然后创建一个**红黑树**，用于存放想要监控的`fd`，还会创建一个**就绪链表**，用于存放就绪的`fd`。
* 调用`epoll_ctl`使用`EPOLL_CTL_ADD`向`epoll`注册文件描述符的时候，会在内核的红黑树创建一个节点，同时为这个`fd`添加一个回调函数，当`fd`上有事件发生时（有数据到达），就调用此`fd`的回调函数，将其加入到就绪链表中。
* 调用`epoll_wait`则只需监控就绪链表里面是否有元素，有就直接返回，没有就等待。如果超时时间到了则返回空的就绪列表。
* `LT`和`ET`的实现：
  * 当一个`fd`上有事件时，内核会把该`fd`插入到就绪链表，当调用`epoll_wait`,内核会把就绪的`fd`拷贝到用户态，然后清空就绪链表。`epoll_wait`会检查这些`fd`,如果是LT模式，且有未处理的事件的时候，又把该`fd`重新放回就绪列表。如果是`ET`模式，无论有没有事件未处理，也不会被再次添加到就绪链表。

##### 6.2.3.2  `select`、`poll`和`epoll`的区别

![image-20200801142557377](https://img-blog.csdnimg.cn/20200809213946774.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxNzYyODYxNzk0,size_16,color_FFFFFF,t_70#pic_center)

### 6.3 大端存储和小端存储

* **大端**

  * 大端是指低字节存放在高地址

* **小端**

  * 小端是指低字节存放在低地址位

* 检测系统是大端还是小端：

  ```cpp
  //通过联合体来判断，因为联合体的所有成员都是从低地址开始存放
  bool func(){
      union test{
          int i;
          char c;
      };
      test t;
      t.i = 1;
      return t.c == 1;
  }
  ```

### 6.4 同步和异步

> 同步和异步关注的是<font color=red>**消息通信机制**</font>

* 所谓**同步**，就是在发出一个*调用*时，在没有得到结果之前，该*调用*就不返回，但是一旦返回，就得到调用的返回值。换句话说，就是*调用者*主动等待这个*调用*的结果
* 所谓**异步**，就是在发出一个*调用*后，这个调用就立即返回了，所以没有返回结果。换句话说，当一个异步调用过程发出后，调用者不会立即得到结果。而是在*调用*完成后，*被调用者*通过状态、通知来告知调用者，或者通过回调函数

### 6.5 阻塞和非阻塞

> 阻塞和非阻塞关注的是<font color=red>**程序在等待调用结果（消息、返回值）时的状态**</font>

* 阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回
* 非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程

### 6.6 多进程、多线程、多协程在什么时候适用



## 七、C++

### 7.1 面试问题

* 类和结构体的区别
  * 结构体的默认访问控制是`public`，类的默认访问控制是`private`
  * 结构体的默认继承是`public`，类的默认继承是`private`
  * <font color=red>除了上述两个不同点之外，C++中的机构体和类没有本质区别，只是一个关键字的问题</font>

* 在基类中的虚函数，在子类中是否也是虚函数
  
  * 在子类中依旧是虚函数
* 早期C语言如何实现多个返回值
  * 全局变量
  * 传递数组指针
  * 传递结构体指针
* 宏定义的问题
  * 只能简单的替换
  * 不能取其地址，因为被宏替换为了一个右值
  * 宏定义不区分数据类型，在遇到重载的时候会有问题

* 内联函数的作用、优缺点、使用场景

  > 当函数被声明为内联时，编译器在编译期会将其内联展开（直接使用代码替换掉函数调用），而不是按通常的函数调用机制进行调用

  * 作用：提高程序运行速度，通过避免函数调用开销
  * 优点：提高程序运行效率，替换宏定义函数
  * 缺点：内联函数增大了可执行程序的体积，内联函数的展开是编译阶段，若内联函数修改，则需新编译整个程序
  * 使用场景：函数代码少于10行或更少才使用内联。

### 7.2 堆和栈的区别

* **管理方式**：栈是由编译器自动控制，无须我们手工控制，堆是由程序员申请和释放，容易产生内存泄露。
* **空间大小**：一般来说，32bit系统下堆可以达到4GB，而栈只有1M，但是栈空间可以修改
* **碎片问题**：对于堆来说，频繁的`new/delete`会造成内存空间的不连续，使程序效率降低；对于栈来说则不会有这个问题，因为栈是先进后出的数据结构
* **分配方式**：堆都是动态分配的；栈可以静态分配和动态分配，静态分配由编译器分配，动态分配由alloca函数进行分配，由编译器实现
* **分配效率**：栈的效率优于堆。栈是机器系统提供的数据结构，底层会对栈提供支持，堆是由`c/c++`函数库提供的，机制复杂

### 7.3 vector

* 底层使用的是数组，初始的大小为0。一个vector占用的空间是三个指针的空间（具体空间随系统版本不同而不同，32位指针4字节，64位指针8字节）。

* vector中的数据成员

  ```cpp
  iterator start;  //目前使用空间的头
  iterator finish;  //目前使用空间的尾
  iterator end_of_storage;  //目前可用空间的尾
  ```

* vector空间的增加每次以两倍递增。每次增加都会重新申请一块空间是之前两倍大小的连续空间，然后将旧值拷贝到新的空间中，最后释放原来的内存。这个过程会使得之前的迭代器失效。

* **vector迭代器失效的问题：**

  ```cpp
  void test_vector() {
  	vector<int> test({ 1,2,3,4,5,6,7,8 });
  	auto begin = test.begin();
  	auto end = test.end();
  	//删除中间元素
  	//test.erase(begin + 1);
  	//cout << *begin << endl;
  	//cout << *end << endl;   // Expesion: vector iterator not dereferencable
  
  	//重新扩容
  	test.push_back(9);
  	cout << *begin << endl;  // Expesion: vector iterator not dereferencable
  	cout << *end << endl;    // Expesion: vector iterator not dereferencable
  
  }
  ```

  * 如果触发vectoe的扩容机制，则所有迭代器失效
  * 如果在vector中间删除元素，该元素之后的迭代器失效，之前的迭代器还可以使用

### 7.4 hashtable

* 解决hash冲突的方式是开链法
* hashtable表格大小虽然不要求其为质数，但SGI STL任然以质数来设计表格大小，其提供28个质数作为扩容时的选择，并提供一个函数选用其中最合适的质数

### 7.5 空间分配器（STL）

#### 7.5.1 std::allocator

SGI STL定义了std::allocator，但并未使用，也不推荐使用，主要是因为**效率不佳**，它只对`::operator new/delete`做了一层薄的封装。

#### 7.5.2 std::alloc

* `::operator new/delete`底层使用`malloc`和`free`
* `SGI`设计双层配置器
  * 第一级配置器直接使用`malloc`和`free`
  * 第二级配置器：
    * 当配置空间足够大，大于**128bytes**，则使用第一级配置器
    * 当配置空间足够小，小于**128bytes**，为降低额外的负担则使用复杂的内存池（memory pool）机制
      * 维护16个自由链表，负责16个小型区块次配置能力
      * 内存不足，调用第一级配置器。
* 第一级空间配置器
  * 不做任何处理的情况下，如果内存不足，则直接抛出异常
  * 不能直接使用C++的`new-handler`机制，但可以仿造一个，其作用是**在内存不足时，调用一个自己定义的处理函数**
  * 如果客户端并未指定“内存不足处理例程”，则`oom_malloc`和`oom_realloc`会直接抛出异常。因为这两个函数内部有死循环，会判断客户端是否设置其处理例程，死循环会一直重试释放内存和申请内存
* 第二级空间配置器
  * 每次配置一大块内存，并维护对应的自由链表
  * 下次如果有相同大小的内存，则直接从内存池中取，客户端返还的小额内存，也会被回收到pool中
  * 方便管理，把内存池中的区块提升到8的倍数，所以16个空闲链表各自维护8~128bytes的链表

### 7.6 STL

#### 7.6.1 STL线程安全

一般来说，STL对于多线程的支持仅限于下列两点：

1. **多个读取这是安全的**。即多个线程可以同时读取一个容器中的内容。即此时多个线程调用容器不涉及到写的接口都可以
2. **对于不同容器的多个写入者是安全的**。即多个线程对不同容器的同时写入合法。

想要STL是线程安全的，需要程序员自己控制。通常的解决办法是用开销较小的临界区来做同步：

1. **每次调用容器的成员函数的期间需要锁定**
2. **每个容器返回迭代器的生存期需要锁定**
3. **每个容器在调用算法的执行期需要锁定**

#### 7.6.2 红黑树

>  红黑树是一种二叉平衡搜索树，并且满足一定的规则。

* 所谓**二叉树**，其意义是：”任何节点最多只允许两个子节点“
* 所谓**二叉搜索树**，可提供对数时间的插入和访问。二叉搜索树的放置规则是：任何节点的键值一定大于其左子树节点，并且一定小于其右子树中的每一个节点的键值
* 所谓**平衡二叉树**，指的是任何节点的左右子树的高度相差最多一

<font color=red>**红黑树需要满足的规则**</font>

1. 每个节点不是红就是黑
2. 根节点为黑
3. 如果节点为红，则子节点一定为黑
4. 任一节点至NULL（树尾端），所含的黑节点必须相同
5. 根据规则4，新增节点必须为红；根据规则3，新增节点的父节点必须为黑

#### 7.6.3 Map

> 键值自动排序，所有元素都是pair，底层实现为**红黑树**，键值不允许重复，因为其使用的是红黑树底层的`insert_unique`函数。







### 7.7 C++11

#### 7.7.1 `lambda`

> lambda表达式是C++11引入的一个重要特性之一，来源于函数式编程的概念。一个lambda表达式就是一个可调用的代码单元、一个匿名函数对象。lambda的定义如下：
>
> ```cpp
> [captrue list](parameter list)->return type or exception
> {
>     function body
> }
> eg:
> sort(test.begin(),test.end(),[](const int & lhs,const int & rhs){return lhs < rhs;});
> ```

* 原理：
  * 每当定义一个lambda表达式后，编译器会自动生成一个**匿名类（这个类重载了()运算符）**，我们成为**闭包类型**

#### 7.7.2 右值引用和move语义

> 复制构造函数执行的是深度复制拷贝，因为源对象本身不能被改变。而转移构造函数函数却可以复制指针。把源对象的指针置空，这种形式下是安全的，因为用户不可能再使用这个对象了

* **右值引用**

  可以引用一个右值，右值是指表达式返回的值或者函数返回的栈对象，都是右值。如下：

  ```cpp
  int create(){
      int x = 0;
      retuen x;
  }
  
  int x = 1,y = 2;
  int && temp = create();
  int && xy = x+y;
  ```

  但右值引用一般使用在移动构造函数和移动赋值函数上面，用于转移对象所持有的资源：

  ```cpp
  class Test{
  public:
      Test(int value = 0)m_value(new int(value)){}
      Test(const Test & test){ //复制构造函数
  		m_value = new int(*(test.m_value));
      }
      Test(Test && test){  //移动构造函数
          m_value = test.m_value;
          test.m_value = nullptr;
      }
      
      Test & operator=(const Test & test){  //赋值函数
          auto temp = m_value;
          m_value = new int(*(test.m_value));
          delete temp;
          return *this;
      }
      
      Test & operator=(Test && test){		//移动赋值函数
          m_value = test.m_value;
          test.m_value = nullptr;
      }
      
  private:
      int m_value;
  };
  
  Test create_test(){
      return Test(1)
  }
  
  int main(){
      Test test1(1);
      Test test2(test1);   //复制构造函数
      Test test3(create_test());   //移动构造函数
      
      Test test4 = test1;   //赋值函数
      Test test5 = create_test();  //移动赋值函数
  }
  
  /*
  如果没有重载移动构造函数或者移动赋值函数，编译器就只会使用复制构造函数或者赋值函数。
  如果重载了，编译器会根据是左值还是右值来调用不同函数
  */
  ```

* **move语义**

  > std::move仅仅是简单地将左值转化为右值，它本身并没有转移任何东西，它仅仅是让对象可转移。

  可以使用在初始化`unique_ptr`的时候。

  ```cpp
  unique_ptr<int>t1(new int(1));  // ok
  unique_ptr<int>t2(t2);  // error  unique_ptr只允许调用移动构造函数
  unique_ptr<int>t3(std::move(t1));  //ok  std::move()将t1变为右值
  ```

  

### 7.8 内存泄漏

#### 7.8.1 内存泄漏的定义

> 一般来说我们常说的内存泄露是指堆内存的泄露。堆内存是指程序从堆中分配的、大小任意的、使用完后必须显示释放的内存。程序一般使用malloc、realloc、new等函数或者运算符从堆中申请内存，使用完之后，程序负责相应的调用free和delete释放该内存块，否则这块内存就不能被再次使用，我们就说这块内存泄露了。

#### 7.8.2 内存泄漏的发生方式

1. 常发性内存泄露。发生内存泄露的代码会被多次执行到，每次执行就会导致一块内存泄露
2. 偶发性内存泄露。发生内存泄露的代码只有在某些特定环境或者操作过程中才会发生。
3. 一次性内存泄露。发生内存泄露的代码只会执行一次，或者由于算法的缺陷，导致总会有且仅有一块内存发生泄露
4. 隐式内存泄露。程序在运行过程中不停的分配内存，但是直到结束的时候才释放内存。

#### 7.8.2 检测内存泄漏的工具

* **Visual Leak Detecter**

  * 应用环境：Windows + VC
  * 编程语言：C/C++
  * 使用方法：只需包含头文件`vld.h`,并添加提供的lib
  * 结果输出：输出到VC的调试窗口中
  * 设计原理：注册`_CrtSetAllockHook`钩子函数，使用VC自带的CRT Debug Heap
  * 优缺点：可以获得内存泄露点的调用堆栈，可以得到内存泄露的完整数据

* **mtrace**

  * 应用环境：Linux GLIBC
  * 编程语言：C
  * 使用方法：包含头文件`mchech.h`,定以环境变量`MALLOC_TRACE`为输出文件名，程序开始时调用`mtacr()`即可
  * 结果输出：用户指定的文件
  * 设计思路：为`malloc`、`realloc`、`free`函数添加钩子函数，记录每一对`malloc-free`的执行
  * 优缺点：只能检查使用`malloc/realloc/free`造成的内存泄露

* **valgrind**

  * 应用环境：Linux
  * 使用方法：加入`memwatch.h`,编译时加上`-DMEMWATCH  -DMW_STDIO`及`memwatch.c`
  * 结果输出：输出文件名称为`memwatch.log`，在执行期间，错误提示显示到stdout上
  * 设计思路：根据软件的内存操作维护一个有效地址空间表和无效地址空间表

* **debug_new**

  * 应用环境：Linux、Windows
  * 使用方法：包含头文件debug_new.h，链接debug_new.cpp

  * 结果输出：控制台console
  * 设计思路：通过重载new和delete操作符来捕获内存申请和释放请求，并在程序内部维护一个全局静态变量的哈希链表。在new操作符中，不仅仅分配用户所要求的内存，而且在每次分配的内存都添加一个头部，存储着此次分配的位置信息和链表指针，new返回的是分配的这块内存加上头部偏移后的值，而在之前已经将此返回值做了hash计算并添加到hash链表中了。delete的时候先根据要释放的指针地址做hash计算，然后再遍历数组hash值处的链表进行查找，如果找到则将该节点移除，未找到就abort。这样程序结束之后，通过检查此链表中是否还有未释放的内存块来确定是否有内存泄露
  * 优缺点：跨平台，仅适用于C++

## 八、其它

### 8.1 程序内存空间

#### <font color=#ff7f27>8.1.1 BSS段（未初始化数据区）</font>

通常用来存放程序中未初始化的全局变量和静态变量的一块内存。BSS段属于静态分配，由系统自动释放。

#### <font color=#ff7f27>8.1.2 data段（数据段）</font>

存放程序中已经初始化的全局变量和静态变量的一块内存区域。

#### <font color=#ff7f27>8.1.3 text段（代码段）</font>

存放程序执行代码的一块内存区域，大小确定，只读。在代码段中也有可能包含一些只读的常数变量，例如字符串常量等

#### <font color=#00a8f3>8.1.4 堆</font>

#### <font color=#00a8f3>8.1.5 栈</font>



## 九、编译原理

### 9.1 源文件到目标文件经历的过程

#### 9.1.1 预处理阶段

> 设有一个`hello.cpp`文件。
>
> 预处理阶段将`.c`文件预编译为`.i`文件
>
> `g++ -E hello.cpp -o hello.i`

* 预处理过程读入源代码，检查包含预处理指令的语句和宏定义，并对源代码进行相应的转化。预处理过程还会删除程序中的注释和多余的空白

#### 9.1.2 编译阶段

> 编译阶段将`.i`文件编译成`.s`文件
>
> `g++ -S hello.i`

编译阶段的任务：

* 词法分析
* 语法分析
* 语义分析
* 中间代码生成
* 代码优化
* 目标代码生成

#### 9.1.3 汇编阶段

> 汇编阶段将`.s`文件汇编为`.o`文件
>
> `g++ -c hello.s`

* 将汇编语言代码编译成为机器语言指令，并最终生成可定位的目标文件格式

#### 9.1.4 链接阶段

> 将源程序调用的库函数编译好的`.o`文件链接到我们的源文件中，链接器的输出结果是可执行的目标程序
>
> `g++ hello.o -o hello`

### 9.2 动态库和静态库

#### 9.2.1 静态库

* 当程序与静态库链接时，库中目标文件所含的所有的将被程序使用的函数的机器码被复制到最终的可执行文件中。这就会导致最终生成的可执行代码量相对较多，相当于编译器将代码补全了。
* 缺点：
  * 占用磁盘和内存空间。静态库会添加到和它连接的每个程序中，而且这些程序运行时被加载到内存会消耗更多的内存
* 静态库在程序编译时会被连接到目标代码中，程序运行时不再需要该静态库

#### 9.2.2 动态库

* 与动态库连接的可执行文件只需要包含他需要的函数的引用表，而不是所有的函数代码，只有在程序执行时，那些需要的代码才被拷贝到内存
* 缺点：
  * 执行速度相对较慢。由于运行时要去连接库会花费一定的时间，执行速度会相对慢点
* 动态库在编译时不会被连接到目标代码中，而是在程序运行时才被载入，因此程序运行时需要动态库

## 十、项目

